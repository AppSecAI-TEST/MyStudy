##SWAT双11技术准备

#####原则：隔离、优化、预案、监控、降级

####数据库

* 问题点

	1. 目前对峰值压力无法预估
	2. DB实际访问细粒度(每个业务、SQL、表)没有统计分析、无法预测和优化

* Action
	1. 压测、容量预估。时间：9月份
	
		* 压测一: 每日拉取线上的日志到嘉兴机房做回放, 指标设定: 128个并发SQL语句, 压测程序提前准备单机的并发数据 (准备多线程下同一时刻的数据,避开PHP的低并发度,实现数据在高并发下回放)。
		* 压测二: 引流至单一DB +  模拟查询流量
		* 压测三: 模拟高并发下事务流量 至单一的交易DB
		
	2. 推动业务迁移表到独立的库、优化慢sql等。时间：9月-10月份
		* 分析目前业务的db表、慢查询情况，推动sql优化
		* 推动业务方将主库的db表迁移到独立的业务库
		* 提前分离mogujie上大数据量和冷数据，做好归档迁移
		
	3. 研究限流、自我保护。时间：9月份
		* 11.11开启拦截非核心业务的慢sql查询
		* DB主站慢sql可以在中间层挡掉
		* 研究TCP的流控组件，探索落地到蘑菇街

####特斯拉
1. 配置中心可用

	业务系统的降级开关依赖配置中心的动态推送功能
2. RoleId自动识别
	
	便于服务化的系统识别请求来源、做降级
	
####IM系统

* 已做技术准备
	1. IM服务器从架构上就消除了单点故障，所有类型的服务进程都多个实例，不会出现单点的软件或硬件故障导致整个IM系统不可用。
	2. 已建立服务进程的监控脚本，每隔10秒钟检测一次，发现被监控的进程崩溃，监控脚本会自动重启被监控的进程，并发送报警短信给开发人员，开发人员需要马上登陆对应的服务器分析并解决问题。
	3. IM服务器现在的最高并发用户数是12万，日消息量为160万左右，高峰时处理100条/s的消息，服务器Load基本为0。现在的架构可以支持100万并发用户数，每秒1000条消息量（压测过支持并发60万用户，每秒1000条消息的情况），预测双11的用户量是现在的2~3倍，现有系统完全可以支持。
	
* 待做技术准备
	1. 异常情况的覆盖测试。模拟各种异常的情况测试服务器、客户端的稳定性，具体参考独嘉客户端异常测试方案，确保服务器、app应用的稳定性
	2. 10月初再作一次压测，测试80万并发用户，1000消息/s
	
* 风险问题点及处理预案
	1. 机房整个不可用，这个需要做异地机房容灾，暂时不考虑这种情况
	2. 端口遭到DDOS攻击，并且造成IM服务瘫痪，临时修改服务器的端口，发布PHP代码。
	3. 用户量大于现在机器的容量限制，根据监控临时加服务器解决，已准备2台临时服务器作为备份
	4. 目前依赖主站数据库做用户登录验证、用户数据获取，如果主库不可用，IM将不可用
	5. 目前依赖Redis做计数器，如果Redis不可用，IM确保整体可以，但未读计数、未读消息推送等不可用
	
* 监控相关
	已建立实时的在线人数、消息数的监控
	服务器基本监控依赖火龙组统一监控
 
####活动促销系统
* 风险点及Action
	1. 促销系统的表都在主库上，极易和其他业务系统互相影响；11.11前将相关表迁移到marketing库。 时间：10.1日前
	2. 促销和活动系统的缓存目前与其他业务共用实例，11.11前需要独立部署，提高隔离性。 时间：10.1日前
	3. 活动页面的高可用、高性能。建立备案，缓存不可用情况下，通过静态化+定时刷新的机制确保活动页面可用。 时间：11.1日前
	4. 对折扣接口、促销规则计算接口做性能压测、容量预估。时间：10月初
	5. 10月份对系统所有功能梳理、分级，支持开关降级。时间：9月份
	6. 结合活动促销具体方案，有针对性的开发反作弊设施，打击店铺、用户通过促销进行作弊。时间：10月中旬
	
	
* 监控报警
	建立下面相关的监控
	1. 建立商品折扣、店铺优惠、促销计算等接口的实时监控。时间：9月份


	目前已有的监控:	
	1. 完善监控现金券发放数，使用数，发放金额，使用金额，引入GMV；
	2. 监控流入店铺的现金券数量；
	3. 监控用户现金券领取相关信息，根据UUID判断是否存在刷券；
	4. 监控用户使用现金券相关信息，判别用户是否存在刷单；


####评价系统

* 风险点及Action
	1. 目前评价列表都从db查询，对db压力较大，后续完善评价的搜索，将评价列表的查询改成搜索。时间：8月下旬
	2. 评价计数、DSR分数基本基于Cache实现，对Cache依赖严重，后续建立搜索作为备案。时间：8月下旬
	3. 评价的缓存与其他业务系统共用实例，后续推进cache独立部署。时间：9月份
	4. 对系统所有功能梳理、分级，支持开关降级。时间：9月份
	
* 监控报警
	建立下面监控：
	1. 评价列表、评价计数、DSR分数三个接口的实时调用情况.时间：8月下旬
	2. 评价新增数量的实时监控。时间：9月上旬
	3. 评价搜索、服务化服务器的基本监控。时间：9月上旬

####团购系统
* 风险点及Action
	1. 目前团购的表在主库zcms下，随着业务的改进，存在大量无用数据，原表的查询性能也比较差，后续推动团购底层的重构，将表迁移到marketing库下。时间：9月中旬
	2. 团购的缓存与其他业务系统共用实例，后续推进cache独立部署。时间：9月中旬
	3. 团购首页对缓存依赖严重，建立备案，缓存不可用情况下，通过静态化+定时刷新的机制确保活动页面可用。时间：9月下旬
	4. 团购detail页面对功能进行分级，非主流程功能异步化，并优化页面的数据库查询性能。时间：9月下旬

* 监控报警
	1. 建立团购list、detail页的实时请求数。时间：8月下旬
	2. 建立app团购list、detail页的实时请求数。 时间：8月下旬

####店铺系统
* 风险点及Action

	1. 建设店铺中心，将表迁移到marketing库，避免与其他业务系统相互影响。时间：9月上旬
	2. 独立部署店铺缓存实例，避免与其他业务系统相互影响。时间：9月上旬
	3. 店铺页面头部优化，考虑静态化实现。时间：9月上旬
	4. 优化店铺装修的实现，去除对TFS的强依赖。时间：8月下旬
	5. 梳理业务功能优先级，开关支持降级。时间：9月下旬

* 监控报警
	1. 监控店铺中心核心服务的请求数。时间：9月上旬
	2. 店铺服务化服务器的基本监控。时间：9月上旬

####垂直产品
* 风险点及Action
	1. 活动页面优化对cache的使用，建立基于静态化+定时刷新机制的备案。时间：10月
	2. 优化美妆频道页的cache使用，建立基于静态化+实时刷新机制的备案。时间：9月中旬
	3. 梳理功能优先级，开关支持降级。时间：9月下旬

* 监控及报警
	1. 频道页请求的实时监控。时间：9月上旬
	
